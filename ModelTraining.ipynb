{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Language Selection**:An Indic accented English speech dataset.\n",
        "\n",
        "**Data Acquisition**:Downloded the Svarah dataset\n"
      ],
      "metadata": {
        "id": "rKMeR6q4mj8h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Nmf1sitcQtjq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed82903c-fd89-4ea1-9c88-f94503cc1eff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "from pathlib import Path\n",
        "!pip install pydub\n",
        "\n",
        "from pydub import AudioSegment"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preparation:**\n",
        "\t\tPre-processed  the data to ensure clean, normalised audio inputs and properly formatted transcripts.\n",
        "    \n",
        "**data split:**\n",
        "\t\tSplited the data into training, validation, and testing sets in an 80/10/10 ratio."
      ],
      "metadata": {
        "id": "IumBW8ppnDav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to manifest files and desired output directories\n",
        "manifest_files = ['svarah_manifest.json', 'saa_l1_manifest.json']\n",
        "output_dir = 'processed_data/'\n",
        "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "rns0gSKXTrUl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET_SAMPLE_RATE = 22050"
      ],
      "metadata": {
        "id": "ss4opNSUbpSO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_manifest(manifest_path=\"/content/saa_l1_manifest.json\"):\n",
        "    \"\"\"Loads and parses the JSON manifest.\"\"\"\n",
        "    with open(manifest_path, 'r', encoding='utf-8') as f:\n",
        "        import json\n",
        "        data = [json.loads(line) for line in f] # This line was indented, causing the error.\n",
        "    return data # Removing the extra return and data assignment inside with open"
      ],
      "metadata": {
        "id": "tOxw9bZJbu_M"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "# Define target sample rate and output directory\n",
        "TARGET_SAMPLE_RATE = 16000  # Example, modify according to your requirement\n",
        "output_dir = '/content/drive/MyDrive/audio'  # Specify your output directory\n",
        "\n",
        "def preprocess_audio(output_dir):\n",
        "    \"\"\"Resamples audio if necessary and returns path to processed file.\"\"\"\n",
        "    audio = AudioSegment.from_wav()  # Load the audio file\n",
        "    if audio.frame_rate != TARGET_SAMPLE_RATE:\n",
        "        audio = audio.set_frame_rate(TARGET_SAMPLE_RATE)  # Resample if needed\n",
        "\n",
        "    # Save resampled audio\n",
        "    processed_path = os.path.join(output_dir, os.path.basename(output_dir))\n",
        "    audio.export(processed_path, format=\"wav\")  # Export as WAV\n",
        "    return processed_path\n"
      ],
      "metadata": {
        "id": "0SB31ieTceXY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(data, train_ratio=0.8, val_ratio=0.1):\n",
        "    \"\"\"Split data into train, validation, and test sets.\"\"\"\n",
        "    random.shuffle(data)\n",
        "    total = len(data)\n",
        "    train_end = int(train_ratio * total)\n",
        "    val_end = train_end + int(val_ratio * total)\n",
        "    return data[:train_end], data[train_end:val_end], data[val_end:]"
      ],
      "metadata": {
        "id": "7F1U5URycxLE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "# Define target sample rate and output directory\n",
        "TARGET_SAMPLE_RATE = 16000  # Example, modify according to your requirement\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "# Define target sample rate and output directory\n",
        "TARGET_SAMPLE_RATE = 16000  # Example, modify according to your requirement\n",
        "output_dir = '/content/drive/MyDrive/audio'  # Specify your output directory\n",
        "\n",
        "def preprocess_audio(audio_file_path, output_dir): # Added audio_file_path as argument\n",
        "    \"\"\"Resamples audio if necessary and returns path to processed file.\"\"\"\n",
        "    audio = AudioSegment.from_wav(audio_file_path)  # Load the audio file using the provided path\n",
        "    if audio.frame_rate != TARGET_SAMPLE_RATE:\n",
        "        audio = audio.set_frame_rate(TARGET_SAMPLE_RATE)  # Resample if needed\n",
        "\n",
        "    # Save resampled audio\n",
        "    processed_path = os.path.join(output_dir, os.path.basename(audio_file_path)) # Use audio_file_path for basename\n",
        "    audio.export(processed_path, format=\"wav\")  # Export as WAV\n",
        "    return processed_path\n",
        "    if audio.frame_rate != TARGET_SAMPLE_RATE:\n",
        "        audio = audio.set_frame_rate(TARGET_SAMPLE_RATE)  # Resample if needed\n",
        "\n",
        "    # Save resampled audio\n",
        "    processed_path = os.path.join(output_dir, os.path.basename('/content/drive/MyDrive/audio')) # Use audio_file_path for basename\n",
        "    audio.export(processed_path, format=\"wav\")  # Export as WAV\n",
        "    return processed_path\n"
      ],
      "metadata": {
        "id": "UEkcJtQghssS"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training, validation, and test sets\n",
        "train_data, val_data, test_data = split_data(all_data)"
      ],
      "metadata": {
        "id": "fnUwte6El6uF"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_manifest(data, filename):\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        for entry in data:\n",
        "            json.dump(entry, f)\n",
        "            f.write('\\n')"
      ],
      "metadata": {
        "id": "YrRgIWqamJE2"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_manifest(train_data, os.path.join(output_dir, 'train_manifest.json'))\n",
        "save_manifest(val_data, os.path.join(output_dir, 'val_manifest.json'))\n",
        "save_manifest(test_data, os.path.join(output_dir, 'test_manifest.json'))"
      ],
      "metadata": {
        "id": "dGXhKNxtmPeA"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data preparation completed. Train, validation, and test manifests saved in:\", output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xvB4aTMmVRz",
        "outputId": "66e7831a-c9a2-4d79-f8bd-a4956ffc1743"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data preparation completed. Train, validation, and test manifests saved in: /content/drive/MyDrive/audio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.**Model Configuration**\n",
        "\t•\tSet up the VITS model by cloning the VITS GitHub repository and configuring it to handle the chosen language and dataset specifics."
      ],
      "metadata": {
        "id": "LLMfJmItnc_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jaywalnut310/vits.git\n",
        "!cd vits\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5z5LXoonwQR",
        "outputId": "cebd044c-36dd-4147-e68f-cd9d6dae7a07"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'vits'...\n",
            "remote: Enumerating objects: 81, done.\u001b[K\n",
            "remote: Total 81 (delta 0), reused 0 (delta 0), pack-reused 81 (from 1)\u001b[K\n",
            "Receiving objects: 100% (81/81), 3.33 MiB | 17.88 MiB/s, done.\n",
            "Resolving deltas: 100% (22/22), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install python3.10-venv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WC1dlypqGol",
        "outputId": "f7720b88-19cd-4193-f214-9ae3efc314ab"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r0% [Waiting for headers] [1 InRelease 12.7 kB/129 kB 10%] [Connected to cloud.r-project.org (3.171.8\r                                                                                                    \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [1 InRelease 129 kB/129 kB 100%] [Connected to cloud.r-project.org (3.171.8\r                                                                                                    \rGet:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\r                                                                                                    \rGet:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r0% [3 InRelease 79.3 kB/128 kB 62%] [Connected to r2u.stat.illinois.edu (192.17.190.167)] [Waiting f\r0% [Waiting for headers] [Connected to r2u.stat.illinois.edu (192.17.190.167)] [Waiting for headers]\r                                                                                                    \rGet:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "\r                                                                                                    \rGet:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,163 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,391 kB]\n",
            "Get:13 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [59.5 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,319 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,672 kB]\n",
            "Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,107 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,452 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,446 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,610 kB]\n",
            "Fetched 23.6 MB in 3s (6,843 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3-pip-whl python3-setuptools-whl\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip-whl python3-setuptools-whl python3.10-venv\n",
            "0 upgraded, 3 newly installed, 0 to remove and 59 not upgraded.\n",
            "Need to get 2,474 kB of archives.\n",
            "After this operation, 2,885 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip-whl all 22.0.2+dfsg-1ubuntu0.5 [1,680 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-setuptools-whl all 59.6.0-1.2ubuntu0.22.04.2 [788 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3.10-venv amd64 3.10.12-1~22.04.6 [5,722 B]\n",
            "Fetched 2,474 kB in 0s (7,061 kB/s)\n",
            "Selecting previously unselected package python3-pip-whl.\n",
            "(Reading database ... 123623 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-pip-whl_22.0.2+dfsg-1ubuntu0.5_all.deb ...\n",
            "Unpacking python3-pip-whl (22.0.2+dfsg-1ubuntu0.5) ...\n",
            "Selecting previously unselected package python3-setuptools-whl.\n",
            "Preparing to unpack .../python3-setuptools-whl_59.6.0-1.2ubuntu0.22.04.2_all.deb ...\n",
            "Unpacking python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.2) ...\n",
            "Selecting previously unselected package python3.10-venv.\n",
            "Preparing to unpack .../python3.10-venv_3.10.12-1~22.04.6_amd64.deb ...\n",
            "Unpacking python3.10-venv (3.10.12-1~22.04.6) ...\n",
            "Setting up python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.2) ...\n",
            "Setting up python3-pip-whl (22.0.2+dfsg-1ubuntu0.5) ...\n",
            "Setting up python3.10-venv (3.10.12-1~22.04.6) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m venv venv\n"
      ],
      "metadata": {
        "id": "vAE9uvd_rCdj"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!venv/bin/pip install --upgrade pip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMl1683ErHsW",
        "outputId": "95305b8f-5e8f-4ae7-add4-08ab3938df33"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in ./venv/lib/python3.10/site-packages (22.0.2)\n",
            "Collecting pip\n",
            "  Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 22.0.2\n",
            "    Uninstalling pip-22.0.2:\n",
            "      Successfully uninstalled pip-22.0.2\n",
            "Successfully installed pip-24.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch librosa numpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLw2Au_0rMhW",
        "outputId": "fc9d6ab9-77d9-431f-82f0-ca051dc73ca8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3VqosrMrSgg",
        "outputId": "b5878d2e-18aa-4401-b818-43666c53ec96"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "281474976883984_f3332_chunk_0.txt   281474976893839_f3333_chunk_2.txt\n",
            "281474976883984_f3332_chunk_0.wav   281474976893839_f3333_chunk_2.wav\n",
            "281474976883989_f3285_chunk_0.txt   281474976893839_f3333_chunk_3.txt\n",
            "281474976883989_f3285_chunk_0.wav   281474976893839_f3333_chunk_3.wav\n",
            "281474976883989_f3285_chunk_1.txt   281474976893850_f3335_chunk_0.txt\n",
            "281474976883989_f3285_chunk_1.wav   281474976893850_f3335_chunk_0.wav\n",
            "281474976883989_f3285_chunk_2.txt   281474976893850_f3335_chunk_10.txt\n",
            "281474976883989_f3285_chunk_2.wav   281474976893850_f3335_chunk_10.wav\n",
            "281474976883989_f3285_chunk_3.txt   281474976893850_f3335_chunk_11.txt\n",
            "281474976883989_f3285_chunk_3.wav   281474976893850_f3335_chunk_11.wav\n",
            "281474976883989_f3285_chunk_4.txt   281474976893850_f3335_chunk_1.txt\n",
            "281474976883989_f3285_chunk_4.wav   281474976893850_f3335_chunk_1.wav\n",
            "281474976883989_f3285_chunk_5.txt   281474976893850_f3335_chunk_2.txt\n",
            "281474976883989_f3285_chunk_5.wav   281474976893850_f3335_chunk_2.wav\n",
            "281474976884119_f3327_chunk_0.txt   281474976893850_f3335_chunk_3.txt\n",
            "281474976884119_f3327_chunk_0.wav   281474976893850_f3335_chunk_3.wav\n",
            "281474976884126_f3274_chunk_0.txt   281474976893850_f3335_chunk_4.txt\n",
            "281474976884126_f3274_chunk_0.wav   281474976893850_f3335_chunk_4.wav\n",
            "281474976884126_f3274_chunk_1.txt   281474976893850_f3335_chunk_5.txt\n",
            "281474976884126_f3274_chunk_1.wav   281474976893850_f3335_chunk_5.wav\n",
            "281474976884126_f3274_chunk_2.txt   281474976893850_f3335_chunk_6.txt\n",
            "281474976884126_f3274_chunk_2.wav   281474976893850_f3335_chunk_6.wav\n",
            "281474976884126_f3274_chunk_3.txt   281474976893850_f3335_chunk_7.txt\n",
            "281474976884126_f3274_chunk_3.wav   281474976893850_f3335_chunk_7.wav\n",
            "281474976884126_f3274_chunk_4.txt   281474976893850_f3335_chunk_8.txt\n",
            "281474976884126_f3274_chunk_4.wav   281474976893850_f3335_chunk_8.wav\n",
            "281474976884126_f3274_chunk_5.txt   281474976893850_f3335_chunk_9.txt\n",
            "281474976884126_f3274_chunk_5.wav   281474976893850_f3335_chunk_9.wav\n",
            "281474976884129_f3284_chunk_0.txt   281474976893991_f3340_chunk_0.txt\n",
            "281474976884129_f3284_chunk_0.wav   281474976893991_f3340_chunk_0.wav\n",
            "281474976884129_f3284_chunk_1.txt   281474976894267_f3266_chunk_0.txt\n",
            "281474976884129_f3284_chunk_1.wav   281474976894267_f3266_chunk_0.wav\n",
            "281474976884129_f3284_chunk_2.txt   281474976894267_f3266_chunk_10.txt\n",
            "281474976884129_f3284_chunk_2.wav   281474976894267_f3266_chunk_10.wav\n",
            "281474976884129_f3284_chunk_3.txt   281474976894267_f3266_chunk_11.txt\n",
            "281474976884129_f3284_chunk_3.wav   281474976894267_f3266_chunk_11.wav\n",
            "281474976884129_f3284_chunk_4.txt   281474976894267_f3266_chunk_12.txt\n",
            "281474976884129_f3284_chunk_4.wav   281474976894267_f3266_chunk_12.wav\n",
            "281474976884129_f3284_chunk_5.txt   281474976894267_f3266_chunk_13.txt\n",
            "281474976884129_f3284_chunk_5.wav   281474976894267_f3266_chunk_13.wav\n",
            "281474976884136_f3328_chunk_0.txt   281474976894267_f3266_chunk_1.txt\n",
            "281474976884136_f3328_chunk_0.wav   281474976894267_f3266_chunk_1.wav\n",
            "281474976884136_f3328_chunk_1.txt   281474976894267_f3266_chunk_2.txt\n",
            "281474976884136_f3328_chunk_1.wav   281474976894267_f3266_chunk_2.wav\n",
            "281474976884136_f3328_chunk_2.txt   281474976894267_f3266_chunk_3.txt\n",
            "281474976884136_f3328_chunk_2.wav   281474976894267_f3266_chunk_3.wav\n",
            "281474976884624_f3310_chunk_0.txt   281474976894267_f3266_chunk_4.txt\n",
            "281474976884624_f3310_chunk_0.wav   281474976894267_f3266_chunk_4.wav\n",
            "281474976884627_f3339_chunk_0.txt   281474976894267_f3266_chunk_5.txt\n",
            "281474976884627_f3339_chunk_0.wav   281474976894267_f3266_chunk_5.wav\n",
            "281474976884627_f3339_chunk_10.txt  281474976894267_f3266_chunk_6.txt\n",
            "281474976884627_f3339_chunk_10.wav  281474976894267_f3266_chunk_6.wav\n",
            "281474976884627_f3339_chunk_11.txt  281474976894267_f3266_chunk_7.txt\n",
            "281474976884627_f3339_chunk_11.wav  281474976894267_f3266_chunk_7.wav\n",
            "281474976884627_f3339_chunk_12.txt  281474976894267_f3266_chunk_8.txt\n",
            "281474976884627_f3339_chunk_12.wav  281474976894267_f3266_chunk_8.wav\n",
            "281474976884627_f3339_chunk_13.txt  281474976894267_f3266_chunk_9.txt\n",
            "281474976884627_f3339_chunk_13.wav  281474976894267_f3266_chunk_9.wav\n",
            "281474976884627_f3339_chunk_14.txt  281474976894273_f3279_chunk_0.txt\n",
            "281474976884627_f3339_chunk_14.wav  281474976894273_f3279_chunk_0.wav\n",
            "281474976884627_f3339_chunk_15.txt  281474976894273_f3279_chunk_10.txt\n",
            "281474976884627_f3339_chunk_15.wav  281474976894273_f3279_chunk_10.wav\n",
            "281474976884627_f3339_chunk_16.txt  281474976894273_f3279_chunk_11.txt\n",
            "281474976884627_f3339_chunk_16.wav  281474976894273_f3279_chunk_11.wav\n",
            "281474976884627_f3339_chunk_1.txt   281474976894273_f3279_chunk_12.txt\n",
            "281474976884627_f3339_chunk_1.wav   281474976894273_f3279_chunk_12.wav\n",
            "281474976884627_f3339_chunk_2.txt   281474976894273_f3279_chunk_13.txt\n",
            "281474976884627_f3339_chunk_2.wav   281474976894273_f3279_chunk_13.wav\n",
            "281474976884627_f3339_chunk_3.txt   281474976894273_f3279_chunk_14.txt\n",
            "281474976884627_f3339_chunk_3.wav   281474976894273_f3279_chunk_14.wav\n",
            "281474976884627_f3339_chunk_4.txt   281474976894273_f3279_chunk_15.txt\n",
            "281474976884627_f3339_chunk_4.wav   281474976894273_f3279_chunk_15.wav\n",
            "281474976884627_f3339_chunk_5.txt   281474976894273_f3279_chunk_16.txt\n",
            "281474976884627_f3339_chunk_5.wav   281474976894273_f3279_chunk_16.wav\n",
            "281474976884627_f3339_chunk_6.txt   281474976894273_f3279_chunk_17.txt\n",
            "281474976884627_f3339_chunk_6.wav   281474976894273_f3279_chunk_17.wav\n",
            "281474976884627_f3339_chunk_7.txt   281474976894273_f3279_chunk_18.txt\n",
            "281474976884627_f3339_chunk_7.wav   281474976894273_f3279_chunk_18.wav\n",
            "281474976884627_f3339_chunk_8.txt   281474976894273_f3279_chunk_19.txt\n",
            "281474976884627_f3339_chunk_8.wav   281474976894273_f3279_chunk_19.wav\n",
            "281474976884627_f3339_chunk_9.txt   281474976894273_f3279_chunk_1.txt\n",
            "281474976884627_f3339_chunk_9.wav   281474976894273_f3279_chunk_1.wav\n",
            "281474976884633_f3311_chunk_0.txt   281474976894273_f3279_chunk_20.txt\n",
            "281474976884633_f3311_chunk_0.wav   281474976894273_f3279_chunk_20.wav\n",
            "281474976884633_f3311_chunk_1.txt   281474976894273_f3279_chunk_21.txt\n",
            "281474976884633_f3311_chunk_1.wav   281474976894273_f3279_chunk_21.wav\n",
            "281474976884633_f3311_chunk_2.txt   281474976894273_f3279_chunk_2.txt\n",
            "281474976884633_f3311_chunk_2.wav   281474976894273_f3279_chunk_2.wav\n",
            "281474976884633_f3311_chunk_3.txt   281474976894273_f3279_chunk_3.txt\n",
            "281474976884633_f3311_chunk_3.wav   281474976894273_f3279_chunk_3.wav\n",
            "281474976884633_f3311_chunk_4.txt   281474976894273_f3279_chunk_4.txt\n",
            "281474976884633_f3311_chunk_4.wav   281474976894273_f3279_chunk_4.wav\n",
            "281474976884633_f3311_chunk_5.txt   281474976894273_f3279_chunk_5.txt\n",
            "281474976884633_f3311_chunk_5.wav   281474976894273_f3279_chunk_5.wav\n",
            "281474976884633_f3311_chunk_6.txt   281474976894273_f3279_chunk_6.txt\n",
            "281474976884633_f3311_chunk_6.wav   281474976894273_f3279_chunk_6.wav\n",
            "281474976884633_f3311_chunk_7.txt   281474976894273_f3279_chunk_7.txt\n",
            "281474976884633_f3311_chunk_7.wav   281474976894273_f3279_chunk_7.wav\n",
            "281474976884635_f3269_chunk_0.txt   281474976894273_f3279_chunk_8.txt\n",
            "281474976884635_f3269_chunk_0.wav   281474976894273_f3279_chunk_8.wav\n",
            "281474976884635_f3269_chunk_1.txt   281474976894273_f3279_chunk_9.txt\n",
            "281474976884635_f3269_chunk_1.wav   281474976894273_f3279_chunk_9.wav\n",
            "281474976884635_f3269_chunk_2.txt   281474976894794_f3270_chunk_0.txt\n",
            "281474976884635_f3269_chunk_2.wav   281474976894794_f3270_chunk_0.wav\n",
            "281474976884635_f3269_chunk_3.txt   281474976894794_f3270_chunk_1.txt\n",
            "281474976884635_f3269_chunk_3.wav   281474976894794_f3270_chunk_1.wav\n",
            "281474976884635_f3269_chunk_4.txt   281474976894794_f3270_chunk_2.txt\n",
            "281474976884635_f3269_chunk_4.wav   281474976894794_f3270_chunk_2.wav\n",
            "281474976884635_f3269_chunk_5.txt   281474976894794_f3270_chunk_3.txt\n",
            "281474976884635_f3269_chunk_5.wav   281474976894794_f3270_chunk_4.txt\n",
            "281474976884635_f3269_chunk_6.txt   281474976895324_f3309_chunk_0.txt\n",
            "281474976884635_f3269_chunk_6.wav   281474976895324_f3309_chunk_0.wav\n",
            "281474976884635_f3269_chunk_7.txt   281474976895324_f3309_chunk_1.txt\n",
            "281474976884635_f3269_chunk_7.wav   281474976895324_f3309_chunk_1.wav\n",
            "281474976884635_f3269_chunk_8.txt   281474976896706_f3294_chunk_0.txt\n",
            "281474976884635_f3269_chunk_8.wav   281474976896706_f3294_chunk_0.wav\n",
            "281474976884635_f3269_chunk_9.txt   281474976896706_f3294_chunk_1.txt\n",
            "281474976884635_f3269_chunk_9.wav   281474976896706_f3294_chunk_1.wav\n",
            "281474976886870_f3336_chunk_0.txt   281474976896706_f3294_chunk_2.txt\n",
            "281474976886870_f3336_chunk_0.wav   281474976896706_f3294_chunk_2.wav\n",
            "281474976886870_f3336_chunk_1.txt   281474976896706_f3294_chunk_3.txt\n",
            "281474976886870_f3336_chunk_1.wav   281474976896706_f3294_chunk_3.wav\n",
            "281474976886919_f3326_chunk_0.txt   281474976896706_f3294_chunk_4.txt\n",
            "281474976886919_f3326_chunk_0.wav   281474976896706_f3294_chunk_4.wav\n",
            "281474976886984_f3291_chunk_0.txt   281474976896706_f3294_chunk_5.txt\n",
            "281474976886984_f3291_chunk_0.wav   281474976896706_f3294_chunk_5.wav\n",
            "281474976886997_f3292_chunk_0.txt   281474976896770_f3298_chunk_0.txt\n",
            "281474976886997_f3292_chunk_0.wav   281474976896770_f3298_chunk_0.wav\n",
            "281474976886997_f3292_chunk_1.txt   281474976896770_f3298_chunk_1.txt\n",
            "281474976886997_f3292_chunk_1.wav   281474976896770_f3298_chunk_1.wav\n",
            "281474976886997_f3292_chunk_2.txt   281474976896770_f3298_chunk_2.txt\n",
            "281474976886997_f3292_chunk_2.wav   281474976896770_f3298_chunk_2.wav\n",
            "281474976886997_f3292_chunk_3.txt   281474976896770_f3298_chunk_3.txt\n",
            "281474976886997_f3292_chunk_3.wav   281474976896770_f3298_chunk_3.wav\n",
            "281474976886997_f3292_chunk_4.txt   281474976896770_f3298_chunk_4.txt\n",
            "281474976886997_f3292_chunk_4.wav   281474976896770_f3298_chunk_4.wav\n",
            "281474976887082_f3312_chunk_0.txt   281474976896770_f3298_chunk_5.txt\n",
            "281474976887082_f3312_chunk_0.wav   281474976896770_f3298_chunk_5.wav\n",
            "281474976887082_f3312_chunk_1.txt   281474976896770_f3298_chunk_6.txt\n",
            "281474976887082_f3312_chunk_1.wav   281474976896770_f3298_chunk_6.wav\n",
            "281474976887082_f3312_chunk_2.txt   281474976896770_f3298_chunk_7.txt\n",
            "281474976887082_f3312_chunk_2.wav   281474976896770_f3298_chunk_7.wav\n",
            "281474976887082_f3312_chunk_3.txt   281474976897395_f3303_chunk_0.txt\n",
            "281474976887082_f3312_chunk_3.wav   281474976897395_f3303_chunk_0.wav\n",
            "281474976887082_f3312_chunk_4.txt   281474976897395_f3303_chunk_1.txt\n",
            "281474976887082_f3312_chunk_4.wav   281474976897395_f3303_chunk_1.wav\n",
            "281474976887085_f3313_chunk_0.txt   281474976897395_f3303_chunk_2.txt\n",
            "281474976887085_f3313_chunk_0.wav   281474976897395_f3303_chunk_2.wav\n",
            "281474976887085_f3313_chunk_1.txt   281474976897395_f3303_chunk_3.txt\n",
            "281474976887085_f3313_chunk_1.wav   281474976897395_f3303_chunk_3.wav\n",
            "281474976887171_f3278_chunk_0.txt   281474976897395_f3303_chunk_4.txt\n",
            "281474976887171_f3278_chunk_0.wav   281474976897395_f3303_chunk_4.wav\n",
            "281474976887171_f3278_chunk_10.txt  281474976897395_f3303_chunk_5.txt\n",
            "281474976887171_f3278_chunk_10.wav  281474976897395_f3303_chunk_5.wav\n",
            "281474976887171_f3278_chunk_11.txt  281474976897395_f3303_chunk_6.txt\n",
            "281474976887171_f3278_chunk_11.wav  281474976897395_f3303_chunk_6.wav\n",
            "281474976887171_f3278_chunk_1.txt   281474976897395_f3303_chunk_7.txt\n",
            "281474976887171_f3278_chunk_1.wav   281474976897395_f3303_chunk_7.wav\n",
            "281474976887171_f3278_chunk_2.txt   281474976897397_f3302_chunk_0.txt\n",
            "281474976887171_f3278_chunk_2.wav   281474976897397_f3302_chunk_0.wav\n",
            "281474976887171_f3278_chunk_3.txt   281474976897397_f3302_chunk_1.txt\n",
            "281474976887171_f3278_chunk_3.wav   281474976897397_f3302_chunk_1.wav\n",
            "281474976887171_f3278_chunk_4.txt   281474976897397_f3302_chunk_2.txt\n",
            "281474976887171_f3278_chunk_4.wav   281474976897397_f3302_chunk_2.wav\n",
            "281474976887171_f3278_chunk_5.txt   281474976897397_f3302_chunk_3.txt\n",
            "281474976887171_f3278_chunk_5.wav   281474976897397_f3302_chunk_3.wav\n",
            "281474976887171_f3278_chunk_6.txt   281474976897397_f3302_chunk_4.txt\n",
            "281474976887171_f3278_chunk_6.wav   281474976897397_f3302_chunk_4.wav\n",
            "281474976887171_f3278_chunk_7.txt   281474976897397_f3302_chunk_5.txt\n",
            "281474976887171_f3278_chunk_7.wav   281474976897397_f3302_chunk_5.wav\n",
            "281474976887171_f3278_chunk_8.txt   281474976897397_f3302_chunk_6.txt\n",
            "281474976887171_f3278_chunk_8.wav   281474976897397_f3302_chunk_6.wav\n",
            "281474976887171_f3278_chunk_9.txt   281474976897397_f3302_chunk_7.txt\n",
            "281474976887171_f3278_chunk_9.wav   281474976897397_f3302_chunk_7.wav\n",
            "281474976887648_f3337_chunk_0.txt   281474976897397_f3302_chunk_8.txt\n",
            "281474976887648_f3337_chunk_0.wav   281474976897397_f3302_chunk_8.wav\n",
            "281474976887648_f3337_chunk_1.txt   281474976897397_f3302_chunk_9.txt\n",
            "281474976887648_f3337_chunk_1.wav   281474976897397_f3302_chunk_9.wav\n",
            "281474976887656_f3338_chunk_0.txt   281474976897400_f3290_chunk_0.txt\n",
            "281474976887656_f3338_chunk_0.wav   281474976897400_f3290_chunk_0.wav\n",
            "281474976887656_f3338_chunk_1.txt   281474976897400_f3290_chunk_1.txt\n",
            "281474976887656_f3338_chunk_1.wav   281474976897400_f3290_chunk_1.wav\n",
            "281474976887660_f3286_chunk_0.txt   281474976897400_f3290_chunk_2.txt\n",
            "281474976887660_f3286_chunk_0.wav   281474976897400_f3290_chunk_2.wav\n",
            "281474976887660_f3286_chunk_1.txt   281474976897400_f3290_chunk_3.txt\n",
            "281474976887660_f3286_chunk_1.wav   281474976897400_f3290_chunk_3.wav\n",
            "281474976887660_f3286_chunk_2.txt   281474976897400_f3290_chunk_4.txt\n",
            "281474976887660_f3286_chunk_2.wav   281474976897400_f3290_chunk_4.wav\n",
            "281474976887660_f3286_chunk_3.txt   281474976897400_f3290_chunk_5.txt\n",
            "281474976887660_f3286_chunk_3.wav   281474976897400_f3290_chunk_5.wav\n",
            "281474976887660_f3286_chunk_4.txt   281474976897711_f3329_chunk_0.txt\n",
            "281474976887660_f3286_chunk_4.wav   281474976897711_f3329_chunk_0.wav\n",
            "281474976887660_f3286_chunk_5.txt   281474976897718_f3330_chunk_0.txt\n",
            "281474976887660_f3286_chunk_5.wav   281474976897718_f3330_chunk_0.wav\n",
            "281474976887707_f3323_chunk_0.txt   281474976897722_f3331_chunk_0.txt\n",
            "281474976887707_f3323_chunk_0.wav   281474976897722_f3331_chunk_0.wav\n",
            "281474976887707_f3323_chunk_1.txt   281474976897722_f3331_chunk_1.txt\n",
            "281474976887707_f3323_chunk_1.wav   281474976897722_f3331_chunk_1.wav\n",
            "281474976887707_f3323_chunk_2.txt   281474976898391_f3297_chunk_0.txt\n",
            "281474976887707_f3323_chunk_2.wav   281474976898391_f3297_chunk_0.wav\n",
            "281474976887707_f3323_chunk_3.txt   281474976898391_f3297_chunk_1.txt\n",
            "281474976887707_f3323_chunk_3.wav   281474976898391_f3297_chunk_1.wav\n",
            "281474976887707_f3323_chunk_4.txt   281474976898391_f3297_chunk_2.txt\n",
            "281474976887707_f3323_chunk_4.wav   281474976898391_f3297_chunk_2.wav\n",
            "281474976887707_f3323_chunk_5.txt   281474976899963_f3295_chunk_0.txt\n",
            "281474976887707_f3323_chunk_5.wav   281474976899963_f3295_chunk_0.wav\n",
            "281474976888146_f3314_chunk_0.txt   281474976899963_f3295_chunk_1.txt\n",
            "281474976888146_f3314_chunk_0.wav   281474976899963_f3295_chunk_1.wav\n",
            "281474976888630_f3289_chunk_0.txt   281474976899963_f3295_chunk_2.txt\n",
            "281474976888630_f3289_chunk_0.wav   281474976899963_f3295_chunk_2.wav\n",
            "281474976888630_f3289_chunk_10.txt  281474976899965_f3296_chunk_0.txt\n",
            "281474976888630_f3289_chunk_10.wav  281474976899965_f3296_chunk_0.wav\n",
            "281474976888630_f3289_chunk_1.txt   281474976899965_f3296_chunk_10.txt\n",
            "281474976888630_f3289_chunk_1.wav   281474976899965_f3296_chunk_10.wav\n",
            "281474976888630_f3289_chunk_2.txt   281474976899965_f3296_chunk_1.txt\n",
            "281474976888630_f3289_chunk_2.wav   281474976899965_f3296_chunk_1.wav\n",
            "281474976888630_f3289_chunk_3.txt   281474976899965_f3296_chunk_2.txt\n",
            "281474976888630_f3289_chunk_4.wav   281474976899965_f3296_chunk_2.wav\n",
            "281474976888630_f3289_chunk_5.txt   281474976899965_f3296_chunk_3.txt\n",
            "281474976888630_f3289_chunk_5.wav   281474976899965_f3296_chunk_3.wav\n",
            "281474976888630_f3289_chunk_6.txt   281474976899965_f3296_chunk_4.txt\n",
            "281474976888630_f3289_chunk_6.wav   281474976899965_f3296_chunk_4.wav\n",
            "281474976888630_f3289_chunk_7.txt   281474976899965_f3296_chunk_5.txt\n",
            "281474976888630_f3289_chunk_7.wav   281474976899965_f3296_chunk_5.wav\n",
            "281474976888630_f3289_chunk_8.txt   281474976899965_f3296_chunk_6.txt\n",
            "281474976888630_f3289_chunk_8.wav   281474976899965_f3296_chunk_6.wav\n",
            "281474976888630_f3289_chunk_9.txt   281474976899965_f3296_chunk_7.txt\n",
            "281474976888630_f3289_chunk_9.wav   281474976899965_f3296_chunk_7.wav\n",
            "281474976888902_f3324_chunk_0.txt   281474976899965_f3296_chunk_8.txt\n",
            "281474976888902_f3324_chunk_0.wav   281474976899965_f3296_chunk_8.wav\n",
            "281474976890753_f3300_chunk_0.txt   281474976900601_f3334_chunk_1.txt\n",
            "281474976890753_f3300_chunk_0.wav   281474976900601_f3334_chunk_1.wav\n",
            "281474976890753_f3300_chunk_1.txt   281474976900601_f3334_chunk_2.txt\n",
            "281474976890753_f3300_chunk_1.wav   281474976900601_f3334_chunk_2.wav\n",
            "281474976890753_f3300_chunk_2.txt   281474976900601_f3334_chunk_3.txt\n",
            "281474976890753_f3300_chunk_2.wav   281474976900601_f3334_chunk_3.wav\n",
            "281474976891401_f3315_chunk_0.txt   281474976900601_f3334_chunk_4.txt\n",
            "281474976891401_f3315_chunk_0.wav   281474976900601_f3334_chunk_4.wav\n",
            "281474976891406_f3282_chunk_0.txt   281474976900601_f3334_chunk_5.txt\n",
            "281474976891406_f3282_chunk_0.wav   281474976900601_f3334_chunk_5.wav\n",
            "281474976891406_f3282_chunk_1.txt   281474976900601_f3334_chunk_6.txt\n",
            "281474976891406_f3282_chunk_1.wav   281474976900601_f3334_chunk_6.wav\n",
            "281474976891407_f3316_chunk_0.txt   281474976900601_f3334_chunk_7.txt\n",
            "281474976891407_f3316_chunk_0.wav   281474976900601_f3334_chunk_7.wav\n",
            "281474976891407_f3316_chunk_1.txt   281474976900601_f3334_chunk_8.txt\n",
            "281474976891407_f3316_chunk_1.wav   281474976900601_f3334_chunk_8.wav\n",
            "281474976891410_f3317_chunk_0.txt   281474976906796_f3304_chunk_0.txt\n",
            "281474976891410_f3317_chunk_0.wav   281474976906796_f3304_chunk_0.wav\n",
            "281474976891411_f3271_chunk_0.txt   281474976909271_f3318_chunk_0.txt\n",
            "281474976891411_f3271_chunk_0.wav   281474976909271_f3318_chunk_0.wav\n",
            "281474976891411_f3271_chunk_1.txt   281474976909273_f3319_chunk_0.txt\n",
            "281474976891411_f3271_chunk_1.wav   281474976909273_f3319_chunk_0.wav\n",
            "281474976891411_f3271_chunk_2.txt   281474976909275_f3320_chunk_0.txt\n",
            "281474976891411_f3271_chunk_2.wav   281474976909275_f3320_chunk_0.wav\n",
            "281474976891413_f3283_chunk_0.txt   281474976909277_f3321_chunk_0.txt\n",
            "281474976891413_f3283_chunk_0.wav   281474976909277_f3321_chunk_0.wav\n",
            "281474976891413_f3283_chunk_1.txt   281474976909277_f3321_chunk_1.txt\n",
            "281474976891413_f3283_chunk_1.wav   281474976909277_f3321_chunk_1.wav\n",
            "281474976891413_f3283_chunk_2.txt   281474976909281_f3322_chunk_0.txt\n",
            "281474976891413_f3283_chunk_2.wav   281474976909281_f3322_chunk_0.wav\n",
            "281474976893028_f3341_chunk_0.txt   281474976925739_f3299_chunk_0.txt\n",
            "281474976893028_f3341_chunk_0.wav   281474976925739_f3299_chunk_0.wav\n",
            "281474976893169_f3301_chunk_0.txt   281474976925739_f3299_chunk_10.txt\n",
            "281474976893169_f3301_chunk_0.wav   281474976925739_f3299_chunk_10.wav\n",
            "281474976893169_f3301_chunk_1.txt   281474976925739_f3299_chunk_1.txt\n",
            "281474976893169_f3301_chunk_1.wav   281474976925739_f3299_chunk_1.wav\n",
            "281474976893169_f3301_chunk_2.txt   281474976925739_f3299_chunk_2.txt\n",
            "281474976893169_f3301_chunk_2.wav   281474976925739_f3299_chunk_2.wav\n",
            "281474976893169_f3301_chunk_3.txt   281474976925739_f3299_chunk_3.txt\n",
            "281474976893169_f3301_chunk_3.wav   281474976925739_f3299_chunk_3.wav\n",
            "281474976893169_f3301_chunk_4.txt   281474976925739_f3299_chunk_4.txt\n",
            "281474976893169_f3301_chunk_4.wav   281474976925739_f3299_chunk_4.wav\n",
            "281474976893169_f3301_chunk_5.txt   281474976925739_f3299_chunk_5.txt\n",
            "281474976893169_f3301_chunk_5.wav   281474976925739_f3299_chunk_5.wav\n",
            "281474976893169_f3301_chunk_6.txt   281474976925739_f3299_chunk_6.txt\n",
            "281474976893169_f3301_chunk_6.wav   281474976925739_f3299_chunk_6.wav\n",
            "281474976893720_f3325_chunk_0.txt   281474976925739_f3299_chunk_7.txt\n",
            "281474976893720_f3325_chunk_0.wav   281474976925739_f3299_chunk_7.wav\n",
            "281474976893720_f3325_chunk_1.txt   281474976925739_f3299_chunk_8.txt\n",
            "281474976893720_f3325_chunk_1.wav   281474976925739_f3299_chunk_8.wav\n",
            "281474976893724_f3273_chunk_0.txt   281474976925739_f3299_chunk_9.txt\n",
            "281474976893724_f3273_chunk_0.wav   281474976925739_f3299_chunk_9.wav\n",
            "281474976893724_f3273_chunk_1.txt   281474976934178_f3305_chunk_0.txt\n",
            "281474976893724_f3273_chunk_1.wav   281474976934178_f3305_chunk_0.wav\n",
            "281474976893724_f3273_chunk_2.txt   281474976934178_f3305_chunk_1.txt\n",
            "281474976893724_f3273_chunk_2.wav   281474976934178_f3305_chunk_1.wav\n",
            "281474976893724_f3273_chunk_3.txt   281474976934180_f3306_chunk_0.txt\n",
            "281474976893724_f3273_chunk_3.wav   281474976934180_f3306_chunk_0.wav\n",
            "281474976893724_f3273_chunk_4.txt   281474976934183_f3307_chunk_0.txt\n",
            "281474976893724_f3273_chunk_4.wav   281474976934183_f3307_chunk_0.wav\n",
            "281474976893724_f3273_chunk_5.txt   281474976934184_f3308_chunk_0.txt\n",
            "281474976893724_f3273_chunk_5.wav   281474976934184_f3308_chunk_0.wav\n",
            "281474976893724_f3273_chunk_6.txt   281474976934184_f3308_chunk_1.txt\n",
            "281474976893724_f3273_chunk_6.wav   281474976934184_f3308_chunk_1.wav\n",
            "281474976893790_f3293_chunk_0.txt   drive\n",
            "281474976893790_f3293_chunk_0.wav   meta_speaker_stats.csv\n",
            "281474976893790_f3293_chunk_1.txt   processed_data\n",
            "281474976893790_f3293_chunk_1.wav   saa_l1_manifest.json\n",
            "281474976893839_f3333_chunk_0.txt   sample_data\n",
            "281474976893839_f3333_chunk_0.wav   svarah_manifest.json\n",
            "281474976893839_f3333_chunk_1.txt   venv\n",
            "281474976893839_f3333_chunk_1.wav   vits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.\t**Model Training:**\n",
        "\t•\tTrain the model using the prepared datasets while monitoring for performance issues and making necessary adjustments."
      ],
      "metadata": {
        "id": "pkX9rMppsTNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd vits\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmLBUQ6IuExl",
        "outputId": "040c0b6b-1e03-41b4-8624-acfc0a9f6656"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/vits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odzMo6aGuIXN",
        "outputId": "84f96ba3-3a7d-4cc4-ae8b-d007fd00b4f6"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attentions.py  filelists\tmel_processing.py  preprocess.py     text\t    utils.py\n",
            "commons.py     inference.ipynb\tmodels.py\t   README.md\t     train_ms.py\n",
            "configs        LICENSE\t\tmodules.py\t   requirements.txt  train.py\n",
            "data_utils.py  losses.py\tmonotonic_align    resources\t     transforms.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --config /content/vits/configs/config.json --data_dir /content/drive/MyDrive/audio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqyAxT40uNop",
        "outputId": "896942ed-f00e-44ba-c689-7986e45b41c2"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-06 04:33:22.235842: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-06 04:33:22.259688: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-06 04:33:22.266805: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-06 04:33:22.283449: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-06 04:33:23.876245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:numba.core.byteflow:bytecode dump:\n",
            ">          0\tNOP(arg=None, lineno=1039)\n",
            "           2\tLOAD_FAST(arg=0, lineno=1042)\n",
            "           4\tLOAD_CONST(arg=1, lineno=1042)\n",
            "           6\tBINARY_SUBSCR(arg=None, lineno=1042)\n",
            "           8\tLOAD_FAST(arg=0, lineno=1042)\n",
            "          10\tLOAD_CONST(arg=2, lineno=1042)\n",
            "          12\tBINARY_SUBSCR(arg=None, lineno=1042)\n",
            "          14\tCOMPARE_OP(arg=4, lineno=1042)\n",
            "          16\tLOAD_FAST(arg=0, lineno=1042)\n",
            "          18\tLOAD_CONST(arg=1, lineno=1042)\n",
            "          20\tBINARY_SUBSCR(arg=None, lineno=1042)\n",
            "          22\tLOAD_FAST(arg=0, lineno=1042)\n",
            "          24\tLOAD_CONST(arg=3, lineno=1042)\n",
            "          26\tBINARY_SUBSCR(arg=None, lineno=1042)\n",
            "          28\tCOMPARE_OP(arg=5, lineno=1042)\n",
            "          30\tBINARY_AND(arg=None, lineno=1042)\n",
            "          32\tRETURN_VALUE(arg=None, lineno=1042)\n",
            "DEBUG:numba.core.byteflow:pending: deque([State(pc_initial=0 nstack_initial=0)])\n",
            "DEBUG:numba.core.byteflow:stack: []\n",
            "DEBUG:numba.core.byteflow:state.pc_initial: State(pc_initial=0 nstack_initial=0)\n",
            "DEBUG:numba.core.byteflow:dispatch pc=0, inst=NOP(arg=None, lineno=1039)\n",
            "DEBUG:numba.core.byteflow:stack []\n",
            "DEBUG:numba.core.byteflow:dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1042)\n",
            "DEBUG:numba.core.byteflow:stack []\n",
            "DEBUG:numba.core.byteflow:dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1042)\n",
            "DEBUG:numba.core.byteflow:stack ['$x2.0']\n",
            "DEBUG:numba.core.byteflow:dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1042)\n",
            "DEBUG:numba.core.byteflow:stack ['$x2.0', '$const4.1']\n",
            "DEBUG:numba.core.byteflow:dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1042)\n",
            "DEBUG:numba.core.byteflow:stack ['$6binary_subscr.2']\n",
            "DEBUG:numba.core.byteflow:dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1042)\n",
            "DEBUG:numba.core.byteflow:stack ['$6binary_subscr.2', '$x8.3']\n",
            "DEBUG:numba.core.byteflow:dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1042)\n",
            "DEBUG:numba.core.byteflow:stack ['$6binary_subscr.2', '$x8.3', '$const10.4']\n",
            "DEBUG:numba.core.byteflow:dispatch pc=14, inst=COMPARE_OP(arg=4, lineno=1042)\n",
            "DEBUG:numba.core.byteflow:stack ['$6binary_subscr.2', '$12binary_subscr.5']\n",
            "DEBUG:numba.core.byteflow:dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1042)\n",
            "DEBUG:numba.core.byteflow:stack ['$14compare_op.6']\n",
            "DEBUG:numba.core.byteflow:dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1042)\n",
            "DEBUG:numba.core.byteflow:stack ['$14compare_op.6', '$x16.7']\n",
            "DEBUG:numba.core.byteflow:dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1042)\n",
            "DEBUG:numba.core.byteflow:stack ['$14compare_op.6', '$x16.7', '$const18.8']\n",
            "DEBUG:numba.core.byteflow:dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1042)\n",
            "DEBUG:numba.core.byteflow:stack ['$14compare_op.6', '$20binary_subscr.9']\n",
            "DEBUG:numba.core.byteflow:dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1042)\n",
            "DEBUG:numba.core.byteflow:stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']\n",
            "DEBUG:numba.core.byteflow:dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1042)\n",
            "DEBUG:numba.core.byteflow:stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']\n",
            "DEBUG:numba.core.byteflow:dispatch pc=28, inst=COMPARE_OP(arg=5, lineno=1042)\n",
            "DEBUG:numba.core.byteflow:stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']\n",
            "DEBUG:numba.core.byteflow:dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1042)\n",
            "DEBUG:numba.core.byteflow:stack ['$14compare_op.6', '$28compare_op.13']\n",
            "DEBUG:numba.core.byteflow:dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1042)\n",
            "DEBUG:numba.core.byteflow:stack ['$30binary_and.14']\n",
            "DEBUG:numba.core.byteflow:end state. edges=[]\n",
            "DEBUG:numba.core.byteflow:-------------------------Prune PHIs-------------------------\n",
            "DEBUG:numba.core.byteflow:Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})\n",
            "DEBUG:numba.core.byteflow:defmap: {}\n",
            "DEBUG:numba.core.byteflow:phismap: defaultdict(<class 'set'>, {})\n",
            "DEBUG:numba.core.byteflow:changing phismap: defaultdict(<class 'set'>, {})\n",
            "DEBUG:numba.core.byteflow:keep phismap: {}\n",
            "DEBUG:numba.core.byteflow:new_out: defaultdict(<class 'dict'>, {})\n",
            "DEBUG:numba.core.byteflow:----------------------DONE Prune PHIs-----------------------\n",
            "DEBUG:numba.core.byteflow:block_infos State(pc_initial=0 nstack_initial=0):\n",
            "AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})\n",
            "DEBUG:numba.core.interpreter:label 0:\n",
            "    x = arg(0, name=x)                       ['x']\n",
            "    $const4.1 = const(int, 0)                ['$const4.1']\n",
            "    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']\n",
            "    $const10.4 = const(int, -1)              ['$const10.4']\n",
            "    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']\n",
            "    $14compare_op.6 = $6binary_subscr.2 > $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']\n",
            "    $const18.8 = const(int, 0)               ['$const18.8']\n",
            "    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']\n",
            "    $const24.11 = const(int, 1)              ['$const24.11']\n",
            "    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']\n",
            "    $28compare_op.13 = $20binary_subscr.9 >= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']\n",
            "    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']\n",
            "    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']\n",
            "    return $32return_value.15                ['$32return_value.15']\n",
            "\n",
            "DEBUG:numba.core.byteflow:bytecode dump:\n",
            ">          0\tNOP(arg=None, lineno=1045)\n",
            "           2\tLOAD_FAST(arg=0, lineno=1048)\n",
            "           4\tLOAD_CONST(arg=1, lineno=1048)\n",
            "           6\tBINARY_SUBSCR(arg=None, lineno=1048)\n",
            "           8\tLOAD_FAST(arg=0, lineno=1048)\n",
            "          10\tLOAD_CONST(arg=2, lineno=1048)\n",
            "          12\tBINARY_SUBSCR(arg=None, lineno=1048)\n",
            "          14\tCOMPARE_OP(arg=0, lineno=1048)\n",
            "          16\tLOAD_FAST(arg=0, lineno=1048)\n",
            "          18\tLOAD_CONST(arg=1, lineno=1048)\n",
            "          20\tBINARY_SUBSCR(arg=None, lineno=1048)\n",
            "          22\tLOAD_FAST(arg=0, lineno=1048)\n",
            "          24\tLOAD_CONST(arg=3, lineno=1048)\n",
            "          26\tBINARY_SUBSCR(arg=None, lineno=1048)\n",
            "          28\tCOMPARE_OP(arg=1, lineno=1048)\n",
            "          30\tBINARY_AND(arg=None, lineno=1048)\n",
            "          32\tRETURN_VALUE(arg=None, lineno=1048)\n",
            "DEBUG:numba.core.byteflow:pending: deque([State(pc_initial=0 nstack_initial=0)])\n",
            "DEBUG:numba.core.byteflow:stack: []\n",
            "DEBUG:numba.core.byteflow:state.pc_initial: State(pc_initial=0 nstack_initial=0)\n",
            "DEBUG:numba.core.byteflow:dispatch pc=0, inst=NOP(arg=None, lineno=1045)\n",
            "DEBUG:numba.core.byteflow:stack []\n",
            "DEBUG:numba.core.byteflow:dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1048)\n",
            "DEBUG:numba.core.byteflow:stack []\n",
            "DEBUG:numba.core.byteflow:dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1048)\n",
            "DEBUG:numba.core.byteflow:stack ['$x2.0']\n",
            "DEBUG:numba.core.byteflow:dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1048)\n",
            "DEBUG:numba.core.byteflow:stack ['$x2.0', '$const4.1']\n",
            "DEBUG:numba.core.byteflow:dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1048)\n",
            "DEBUG:numba.core.byteflow:stack ['$6binary_subscr.2']\n",
            "DEBUG:numba.core.byteflow:dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1048)\n",
            "DEBUG:numba.core.byteflow:stack ['$6binary_subscr.2', '$x8.3']\n",
            "DEBUG:numba.core.byteflow:dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1048)\n",
            "DEBUG:numba.core.byteflow:stack ['$6binary_subscr.2', '$x8.3', '$const10.4']\n",
            "DEBUG:numba.core.byteflow:dispatch pc=14, inst=COMPARE_OP(arg=0, lineno=1048)\n",
            "DEBUG:numba.core.byteflow:stack ['$6binary_subscr.2', '$12binary_subscr.5']\n",
            "DEBUG:numba.core.byteflow:dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1048)\n",
            "DEBUG:numba.core.byteflow:stack ['$14compare_op.6']\n",
            "DEBUG:numba.core.byteflow:dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1048)\n",
            "DEBUG:numba.core.byteflow:stack ['$14compare_op.6', '$x16.7']\n",
            "DEBUG:numba.core.byteflow:dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1048)\n",
            "DEBUG:numba.core.byteflow:stack ['$14compare_op.6', '$x16.7', '$const18.8']\n",
            "DEBUG:numba.core.byteflow:dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1048)\n",
            "DEBUG:numba.core.byteflow:stack ['$14compare_op.6', '$20binary_subscr.9']\n",
            "DEBUG:numba.core.byteflow:dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1048)\n",
            "DEBUG:numba.core.byteflow:stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']\n",
            "DEBUG:numba.core.byteflow:dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1048)\n",
            "DEBUG:numba.core.byteflow:stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']\n",
            "DEBUG:numba.core.byteflow:dispatch pc=28, inst=COMPARE_OP(arg=1, lineno=1048)\n",
            "DEBUG:numba.core.byteflow:stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']\n",
            "DEBUG:numba.core.byteflow:dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1048)\n",
            "DEBUG:numba.core.byteflow:stack ['$14compare_op.6', '$28compare_op.13']\n",
            "DEBUG:numba.core.byteflow:dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1048)\n",
            "DEBUG:numba.core.byteflow:stack ['$30binary_and.14']\n",
            "DEBUG:numba.core.byteflow:end state. edges=[]\n",
            "DEBUG:numba.core.byteflow:-------------------------Prune PHIs-------------------------\n",
            "DEBUG:numba.core.byteflow:Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})\n",
            "DEBUG:numba.core.byteflow:defmap: {}\n",
            "DEBUG:numba.core.byteflow:phismap: defaultdict(<class 'set'>, {})\n",
            "DEBUG:numba.core.byteflow:changing phismap: defaultdict(<class 'set'>, {})\n",
            "DEBUG:numba.core.byteflow:keep phismap: {}\n",
            "DEBUG:numba.core.byteflow:new_out: defaultdict(<class 'dict'>, {})\n",
            "DEBUG:numba.core.byteflow:----------------------DONE Prune PHIs-----------------------\n",
            "DEBUG:numba.core.byteflow:block_infos State(pc_initial=0 nstack_initial=0):\n",
            "AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})\n",
            "DEBUG:numba.core.interpreter:label 0:\n",
            "    x = arg(0, name=x)                       ['x']\n",
            "    $const4.1 = const(int, 0)                ['$const4.1']\n",
            "    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']\n",
            "    $const10.4 = const(int, -1)              ['$const10.4']\n",
            "    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']\n",
            "    $14compare_op.6 = $6binary_subscr.2 < $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']\n",
            "    $const18.8 = const(int, 0)               ['$const18.8']\n",
            "    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']\n",
            "    $const24.11 = const(int, 1)              ['$const24.11']\n",
            "    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']\n",
            "    $28compare_op.13 = $20binary_subscr.9 <= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']\n",
            "    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']\n",
            "    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']\n",
            "    return $32return_value.15                ['$32return_value.15']\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/vits/train.py\", line 18, in <module>\n",
            "    from data_utils import (\n",
            "  File \"/content/vits/data_utils.py\", line 11, in <module>\n",
            "    from text import text_to_sequence, cleaned_text_to_sequence\n",
            "  File \"/content/vits/text/__init__.py\", line 2, in <module>\n",
            "    from text import cleaners\n",
            "  File \"/content/vits/text/cleaners.py\", line 16, in <module>\n",
            "    from unidecode import unidecode\n",
            "ModuleNotFoundError: No module named 'unidecode'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries (assuming you are using TensorFlow/Keras)\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np # Import numpy for data manipulation\n",
        "\n",
        "\n",
        "# Define and compile the model\n",
        "# This is a simple example, replace with your desired model architecture\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Load your data (replace with your actual data loading logic)\n",
        "# Assuming you have training data in X_train and y_train\n",
        "\n",
        "# Example using dummy data for demonstration\n",
        "# Replace this with your actual data loading process\n",
        "num_samples = 1000\n",
        "X_train = np.random.rand(num_samples, 784) # Create random data for X_train\n",
        "y_train = np.random.randint(0, 10, size=(num_samples,)) # Create random labels for y_train\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes=10) # One-hot encode labels\n",
        "\n",
        "\n",
        "\n",
        "# Train the model using model.fit()\n",
        "model.fit(X_train, y_train, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJwHmXY8xBxs",
        "outputId": "241c2ddc-edbe-42f0-9e04-17186ab1104d"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1035 - loss: 2.4369\n",
            "Epoch 2/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1199 - loss: 2.3075\n",
            "Epoch 3/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1484 - loss: 2.2505\n",
            "Epoch 4/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1942 - loss: 2.2163\n",
            "Epoch 5/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2054 - loss: 2.1815\n",
            "Epoch 6/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2792 - loss: 2.0795\n",
            "Epoch 7/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3104 - loss: 2.0384\n",
            "Epoch 8/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3701 - loss: 1.9334\n",
            "Epoch 9/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4102 - loss: 1.8940\n",
            "Epoch 10/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5075 - loss: 1.7921\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7dbbee02d240>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')  # Or the preferred method you're using to save your model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8PWcauvyBpO",
        "outputId": "abfdd5db-09b4-48ac-b4b8-adfd8f197889"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.\t**Model Evaluation:**\n",
        "\t•\tEvaluate the model using validation and test sets to ensure it meets quality standards in audio synthesis.\n"
      ],
      "metadata": {
        "id": "DyVha80XyQBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np # Import numpy for data manipulation\n",
        "\n",
        "\n",
        "# Define and compile the model\n",
        "# This is a simple example, replace with your desired model architecture\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Load your data (replace with your actual data loading logic)\n",
        "# Assuming you have training data in X_train and y_train\n",
        "\n",
        "# Example using dummy data for demonstration\n",
        "# Replace this with your actual data loading process\n",
        "num_samples = 1000\n",
        "X_train = np.random.rand(num_samples, 784) # Create random data for X_train\n",
        "y_train = np.random.randint(0, 10, size=(num_samples,)) # Create random labels for y_train\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes=10) # One-hot encode labels\n",
        "\n",
        "# **Prepare validation and test data**\n",
        "# **Replace with your actual data loading and splitting logic**\n",
        "# **Example using dummy data for demonstration**\n",
        "num_val_samples = 200\n",
        "num_test_samples = 200\n",
        "\n",
        "# Split data into training, validation, and test sets\n",
        "validation_data = X_train[:num_val_samples]\n",
        "validation_labels = y_train[:num_val_samples]\n",
        "test_data = X_train[num_val_samples : num_val_samples + num_test_samples]\n",
        "test_labels = y_train[num_val_samples : num_val_samples + num_test_samples]\n",
        "X_train = X_train[num_val_samples + num_test_samples:]\n",
        "y_train = y_train[num_val_samples + num_test_samples:]\n",
        "\n",
        "\n",
        "\n",
        "# Train the model using model.fit()\n",
        "model.fit(X_train, y_train, epochs=10)\n",
        "\n",
        "# Evaluate the model\n",
        "val_loss, val_accuracy = model.evaluate(validation_data, validation_labels)\n",
        "print(f\"Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}\")\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(test_data, test_labels)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNlePTYYyF2y",
        "outputId": "840484b5-ff77-4915-9eff-f7ccb5790610"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0773 - loss: 2.5923    \n",
            "Epoch 2/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1026 - loss: 2.3302 \n",
            "Epoch 3/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1597 - loss: 2.2530 \n",
            "Epoch 4/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2162 - loss: 2.2055 \n",
            "Epoch 5/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2526 - loss: 2.1477\n",
            "Epoch 6/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2509 - loss: 2.1352 \n",
            "Epoch 7/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3052 - loss: 2.0760 \n",
            "Epoch 8/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3236 - loss: 2.0608\n",
            "Epoch 9/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3730 - loss: 1.9770 \n",
            "Epoch 10/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3890 - loss: 1.9164 \n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0881 - loss: 2.5455  \n",
            "Validation Loss: 2.5181632041931152, Validation Accuracy: 0.09000000357627869\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0818 - loss: 2.6249 \n",
            "Test Loss: 2.556478500366211, Test Accuracy: 0.08500000089406967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='your_loss_function', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "5193FPJK0Gd0"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.**Optimization and Refinement:**\n",
        "\t•\tRefine the model based on feedback and testing to improve its accuracy and performance."
      ],
      "metadata": {
        "id": "-C5KxqAB1M6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Function to load and extract features from an audio file\n",
        "def extract_mel_spectrogram(audio_file):\n",
        "    # Load the audio file\n",
        "    y, sr = librosa.load(audio_file, sr=None)  # y is the audio signal, sr is the sample rate\n",
        "\n",
        "    # Extract Mel spectrogram (128 Mel bands)\n",
        "    # Pass 'y' and 'sr' as keyword arguments\n",
        "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
        "\n",
        "    # Convert the Mel spectrogram to decibel scale\n",
        "    log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
        "\n",
        "    # Return the Mel spectrogram (we transpose it to get time_steps x features)\n",
        "    return log_mel_spectrogram.T  # This is a 2D array: (time_steps, 128)\n",
        "\n",
        "# Example: Load an audio file and extract its features\n",
        "audio_file = '/content/281474976884119_f3327_chunk_0.wav'  # Replace with the path to your audio file\n",
        "train_data = extract_mel_spectrogram(audio_file)\n",
        "\n",
        "# Print the shape of the feature array\n",
        "print(train_data.shape)  # Output shape: (time_steps, 128)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuWBMMIs1WbC",
        "outputId": "f70ab5b5-6d35-4387-eae7-b86f4470285f"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(340, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example list of phonemes (labels) corresponding to the audio file\n",
        "train_labels = ['h', 'e', 'l', 'l', 'o']  # Phonemes for the word 'hello'\n"
      ],
      "metadata": {
        "id": "a6O7Rg9k4J06"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Encode the phoneme labels into integers\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(train_labels)\n",
        "\n",
        "# Optionally, convert the encoded labels to one-hot encoding\n",
        "one_hot_labels = to_categorical(encoded_labels, num_classes=len(label_encoder.classes_))\n",
        "\n",
        "# Print encoded labels and their one-hot version\n",
        "print(encoded_labels)  # [0, 1, 2, 2, 3] (example integer encoding)\n",
        "print(one_hot_labels)  # [[1, 0, 0, 0], [0, 1, 0, 0], ...] (one-hot encoding)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu6NPAM24WUf",
        "outputId": "387a5907-d633-4de0-b3ab-324e4775e790"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 2 2 3]\n",
            "[[0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "!pip install praatio\n",
        "import librosa\n",
        "  # Import tgio module from praatio\n",
        "import numpy as np\n",
        "\n",
        "# ... (rest of the code remains the same)\n",
        "\n",
        "def prepare_data_with_forced_alignment(audio_file, textgrid_file):\n",
        "    \"\"\"\n",
        "    Prepares training data using forced alignment.\n",
        "\n",
        "    Args:\n",
        "        audio_file (str): Path to the audio file.\n",
        "        textgrid_file (str): Path to the TextGrid file.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (train_data, train_labels)\n",
        "    \"\"\"\n",
        "\n",
        "    # Load audio and TextGrid\n",
        "    y, sr = librosa.load(audio_file, sr=None)\n",
        "    tg = tgio.openTextgrid(textgrid_file) # Use tgio.openTextgrid\n",
        "\n",
        "    # ... (rest of the code remains the same)\n",
        "\n",
        "# ... (rest of the code remains the same)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeiTzROJ4Zyv",
        "outputId": "7cf7b7d5-c6f4-48a4-ca61-65ce4bf51640"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: praatio in /usr/local/lib/python3.10/dist-packages (6.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from praatio) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.\t**Deployment:**\n",
        "\t•\tPrepare the model for deployment in a way that allows users to easily convert WAV audio to FLAC using a WebSocket connection."
      ],
      "metadata": {
        "id": "FBTAVs_f7k72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install websockets pydub\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RKZFzmn7o4Q",
        "outputId": "d2693673-dc71-42b6-f131-d9936e1e018e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (13.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nest_asyncio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTCku8ZL78NS",
        "outputId": "3916d122-f2bf-4d6d-81c4-436fdadb871f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IppEKkwi-HKb",
        "outputId": "6df37fe9-53de-4aaf-80f0-9358ae1b5a32"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.1-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.1\n"
          ]
        }
      ]
    }
  ]
}